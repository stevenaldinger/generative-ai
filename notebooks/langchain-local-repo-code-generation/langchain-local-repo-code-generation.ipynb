{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d5d4bf-dadf-4058-8024-9da9e1ebbc89",
   "metadata": {},
   "source": [
    "# Local Code Repo Context for Code Generation with LangChain\n",
    "\n",
    "This example shows how to read in an entire code base, generate embeddings, store those embeddings in a persistent local database, query the database directly for relevant pieces of text, and then how to use the database as a source for an LLM hooked into LangChain to create a code generator with awareness of the repo's style and general context.\n",
    "\n",
    "This was a work-in-progress experiment I abandoned to try to build a framework for generating complex, multiple-file outputs. If something seems strange to you, especially in the prompts, follow your intuition and don't blindly trust the example.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, add a GitHub repo to the data directory. If the repo's name is `my-user/my-repo-name`, then the data directory structure should look like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── repositories\n",
    "│   └── my-user\n",
    "│       └── my-repo-name\n",
    "```\n",
    "\n",
    "\n",
    "Second, set the `github_repo` variable to match the repo name in the `Configure variables` section below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22393a",
   "metadata": {},
   "source": [
    "## ChromaDB Persistence\n",
    "\n",
    "Each notebook that uses ChromaDB follows the same pattern for persistence.\n",
    "\n",
    "If the directory already exists that ChromaDB would be writing it's data to, it will load the existing database. If the directory does not exist, it will create a new database.\n",
    "\n",
    "If you change parameters that affect the embeddings generation (like swapping in a new PDF file), you'll need to delete the database directory to force a new database to be created.\n",
    "\n",
    "This can be done by running the following from the root of the repository. If the ChromaDB directory is `data/chromadb/local_repository`, you'd run the following to delete it:\n",
    "\n",
    "```sh\n",
    "rm -rf data/chromadb/local_repository\n",
    "```\n",
    "\n",
    "or if you run into permissions issues:\n",
    "\n",
    "```sh\n",
    "sudo rm -rf data/chromadb/local_repository\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e25bc",
   "metadata": {},
   "source": [
    "## Configure variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3261cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ****************** [START] Google Cloud project settings ****************** #\n",
    "project =  os.getenv('GCP_PROJECT')\n",
    "location = os.environ.get('GCP_REGION', 'us-central1')\n",
    "# ******************* [END] Google Cloud project settings ******************* #\n",
    "\n",
    "\n",
    "# *********************** [START] Embeddings config ************************* #\n",
    "# set rate limiting options for Vertex AI embeddings\n",
    "embeddings_requests_per_minute = 100\n",
    "embeddings_num_instances_per_batch = 5\n",
    "# *********************** [END] Embeddings config *************************** #\n",
    "\n",
    "\n",
    "# ********************** [START] data directory config ********************** #\n",
    "# local directory to write chroma db persistence to\n",
    "# or pull files like PDFs from to create embeddings\n",
    "from helpers.files import get_data_dir\n",
    "data_dir = get_data_dir()\n",
    "\n",
    "chroma_db_dir = f'{data_dir}/chromadb'\n",
    "chroma_db_local_repo_dir = f'{chroma_db_dir}/local_repository'\n",
    "# *********************** [END] data directory config *********************** #\n",
    "\n",
    "\n",
    "# ********************** [START] LLM data config **************************** #\n",
    "from helpers.files import file_exists\n",
    "\n",
    "collection_name = 'local-repository'\n",
    "load_documents = True\n",
    "if file_exists(chroma_db_local_repo_dir):\n",
    "    load_documents = False\n",
    "# *********************** [END] LLM data config ***************************** #\n",
    "\n",
    "\n",
    "# ********************** [START] repository config ************************** #\n",
    "github_repo = \"imup-io/front-end\"\n",
    "repo_dir = f\"{data_dir}/repositories/{github_repo}\"\n",
    "# *********************** [END] repository config **************************** #\n",
    "\n",
    "\n",
    "# *********************** [START] RAG parameter config ********************** #\n",
    "# experiment with:\n",
    "# - mmr\n",
    "# - similarity\n",
    "db_search_type = \"similarity\"\n",
    "db_search_kwargs = {\"k\": 5}\n",
    "# *********************** [END] RAG parameter config ************************ #\n",
    "\n",
    "\n",
    "# *********************** [START] LLM parameter config ********************** #\n",
    "# Vertex AI model to use for the LLM\n",
    "model_name='code-bison@latest'\n",
    "# model_name='code-bison-32k@latest'\n",
    "\n",
    "# maximum number of model responses generated per prompt\n",
    "candidate_count = 1\n",
    "\n",
    "# determines the maximum amount of text output from one prompt.\n",
    "# a token is approximately four characters.\n",
    "max_output_tokens = 2048\n",
    "\n",
    "# temperature controls the degree of randomness in token selection.\n",
    "# lower temperatures are good for prompts that expect a true or\n",
    "# correct response, while higher temperatures can lead to more\n",
    "# diverse or unexpected results. With a temperature of 0 the highest\n",
    "# probability token is always selected. for most use cases, try\n",
    "# starting with a temperature of 0.2.\n",
    "temperature = 0.1\n",
    "\n",
    "# how verbose the llm and langchain agent is when thinking\n",
    "# through a prompt. you're going to want this set to True\n",
    "# for development so you can debug its thought process\n",
    "verbose = True\n",
    "# *********************** [END] LLM parameter config ************************ #\n",
    "\n",
    "\n",
    "# ********************** [START] Configuration Checks *********************** #\n",
    "if not project:\n",
    "    raise Exception('GCP_PROJECT environment variable not set')\n",
    "# *********************** [END] Configuration Checks ************************ #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62c72d",
   "metadata": {},
   "source": [
    "## Import and Initialize Vertex AI Client\n",
    "\n",
    "This will complain about not having cuda drivers and the GPU not being used. You can safely ignore that. If you want to use the GPU, that's possible in Linux with Docker, but you'll need to set up a non-containerized development environment to use GPUs with MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 05:43:47.649788: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-19 05:43:47.651400: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 05:43:47.669843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 05:43:47.669874: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 05:43:47.669894: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 05:43:47.673734: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 05:43:47.674247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 05:43:48.129982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK version: 1.36.0\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=project, location=location)\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain\n",
    "\n",
    "This doesn't actually initialize anything, it just lets us print the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.0.330\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure LLM with Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=model_name,\n",
    "    max_output_tokens=max_output_tokens,\n",
    "    temperature=temperature,\n",
    "    # top_p=top_p,\n",
    "    # top_k=top_k,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Embeddings Function with Vertex AI\n",
    "\n",
    "There are other options for creating embeddings. I was interested in sticking with Google products here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2436c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.vertexai.VertexAIEmbeddings.html\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    requests_per_minute=embeddings_requests_per_minute,\n",
    "    num_instances_per_batch=embeddings_num_instances_per_batch,\n",
    "    model_name = \"textembedding-gecko@latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050c761",
   "metadata": {},
   "source": [
    "## Configure Retrieval Augmented Generation Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def create_grounding_statement(grounding_context, github_repo, coding_language):\n",
    "    grounding_statement = f\"\"\"\n",
    "{grounding_context}\n",
    "Respond with the syntactically correct & concise code for to the question below. Make sure you follow these rules:\n",
    "1. Always assume a question is referring to the {github_repo} GitHub repository. Use context from the repository's code to understand the interfaces to components as well as how to use them.\n",
    "2. The code should follow the same style as the code in the {github_repo} repository.\n",
    "3. Ensure all the requirements in the question are met. If it is impossible to meet a requirement, respond with \"Impossible to meet requirement: [requirement]\".\n",
    "4. The code should be written in {coding_language}.\n",
    "5. If a .prettierrc file is present in the repository, respect its rules when formatting the code.\n",
    "\"\"\"\n",
    "    return grounding_statement\n",
    "\n",
    "def create_prompt_template(grounding_statement):\n",
    "    prompt_rag_statement = f\"\"\"\n",
    "{grounding_statement}\n",
    "\n",
    "Question:\n",
    "{{question}}\n",
    "\n",
    "Context:\n",
    "{{context}}\n",
    "\n",
    "Helpful Response:\n",
    "\"\"\"\n",
    "\n",
    "    prompt_rag_template = PromptTemplate(\n",
    "        template=prompt_rag_statement,\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    return prompt_rag_template\n",
    "\n",
    "def create_retrieval_qa_chain(llm, prompt_template, retriever):\n",
    "    qa_chain = RetrievalQA.from_llm(\n",
    "        llm=llm,\n",
    "        prompt=prompt_template,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in local directory of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files in /home/steven/work/data/repos-for-search/imup-io/front-end/**/*.ts\n",
      "Searching for files in /home/steven/work/data/repos-for-search/imup-io/front-end/**/*.tsx\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "extensions = ['*.ts', '*.tsx']\n",
    "\n",
    "repo_code_files = []\n",
    "for extension in extensions:\n",
    "    search_string=f\"{repo_dir}/**/{extension}\"\n",
    "    print(f\"Searching for files in {search_string}\")\n",
    "    repo_code_files.extend(glob.glob(search_string, recursive=True))\n",
    "\n",
    "print(len(repo_code_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create documents from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='// jest-dom adds custom jest matchers for asserting on DOM nodes.\\n// allows you to do things like:\\n// expect(element).toHaveTextContent(/react/i)\\n// learn more: https://github.com/testing-library/jest-dom\\n// get a \"document undefined\" error without this: https://jestjs.io/docs/configuration#testenvironment-string\\nimport \\'@testing-library/jest-dom\\'\\n', metadata={'url': '/home/steven/work/data/repos-for-search/imup-io/front-end/jest.setup.ts', 'file_index': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "def extract_code_from_file(file_path):\n",
    "    code = \"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        code = file.read()\n",
    "    return code\n",
    "\n",
    "code_strings = []\n",
    "\n",
    "for i in range(0, len (repo_code_files)):\n",
    "    # TODO: this is a pointless check until I add more languages that\n",
    "    # I don't want to use Language.TS for with RecursiveCharacterTextSplitter\n",
    "    if repo_code_files[i].endswith(\".ts\") or repo_code_files[i].endswith(\".tsx\"):\n",
    "        content = extract_code_from_file(repo_code_files[i])\n",
    "\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            # TODO: attach more metadata\n",
    "            metadata={\"url\": repo_code_files[i], \"file_index\":i}\n",
    "        )\n",
    "\n",
    "        code_strings.append(doc)\n",
    "\n",
    "code_strings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the code documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunk code strings\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.TS,\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "texts = text_splitter.split_documents(code_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings Database\n",
    "\n",
    "This is written with persistence and will not re-create the database if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if load_documents:\n",
    "  # https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html#langchain.vectorstores.chroma.Chroma.from_documents\n",
    "  db = Chroma.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    collection_name=collection_name,\n",
    "    persist_directory=chroma_db_local_repo_dir,\n",
    "  )\n",
    "else:\n",
    "  db = Chroma(\n",
    "    persist_directory=chroma_db_local_repo_dir,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collection_name,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this would be safe to run in all circumstances but\n",
    "# it feels weird to try writing if there are no changes anyway\n",
    "if load_documents:\n",
    "  db.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Code Embeddings Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=db_search_type,\n",
    "    search_kwargs=db_search_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Prompts and Generate Code\n",
    "\n",
    "This was run on a private repository so no one can confirm this, but the things it pulled in from the repo context were:\n",
    "1. absolute import with `@components` as a custom alias set up in that repo\n",
    "2. using anonymous functional component syntax\n",
    "3. delcaring the `FC` type for the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tsx\n",
      "import React, { useState } from 'react';\n",
      "import { ImUpLogo } from '@components/ImUpLogo';\n",
      "import { Button } from 'antd';\n",
      "\n",
      "const ImUpLogoButton: React.FC = () => {\n",
      "  const [rotate, setRotate] = useState(0);\n",
      "\n",
      "  const handleClick = () => {\n",
      "    setRotate((prevRotate) => prevRotate + 90);\n",
      "  };\n",
      "\n",
      "  return (\n",
      "    <Button onClick={handleClick}>\n",
      "      <ImUpLogo\n",
      "        style={{ transform: `rotate(${rotate}deg)` }}\n",
      "        tooltipText=\"imUp.io Logo\"\n",
      "      />\n",
      "    </Button>\n",
      "  );\n",
      "};\n",
      "\n",
      "export default ImUpLogoButton;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "react_grounding_statement = \"\"\"\n",
    "You are a proficient React and typescript developer working with the following libraries:\n",
    "- name: react\n",
    "  version: ^18.2.0\n",
    "- name: antd\n",
    "  version: ^5.9.0\n",
    "- name: \"@testing-library/jest-dom\"\n",
    "  version: ^5.17.0\n",
    "- name: \"@testing-library/react\"\n",
    "  version: ^14.0.0\n",
    "\"\"\"\n",
    "\n",
    "coding_language = \"typescript\"\n",
    "\n",
    "grounding_statement = create_grounding_statement(react_grounding_statement, github_repo, coding_language)\n",
    "prompt_template = create_prompt_template(grounding_statement)\n",
    "\n",
    "qa_chain = create_retrieval_qa_chain(llm, prompt_template, retriever=retriever)\n",
    "\n",
    "query = \"\"\"\n",
    "Create a React component named 'ImUpLogoButton', utilizing imUp's ImUpLogo component satisfying the following requirements:\n",
    "1. The component should be named 'ImUpLogoButton'.\n",
    "2. The ImUpLogo graphic should rotate +90 degrees each time it's clicked.\n",
    "3. The ImUpLogo component's tooltip should say 'imUp.io Logo'.\n",
    "\"\"\"\n",
    "\n",
    "results = qa_chain({\"query\": query})\n",
    "print(results[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```tsx\n",
      "import { FC } from 'react';\n",
      "import { ChartSparkLine as Component } from '@components/index';\n",
      "import { ChartSparkLineUptimeDataProps } from './ChartSparkLineUptimeData.interface';\n",
      "import { useGetUptimeDataQuery } from '@ducks/imup/api/api';\n",
      "\n",
      "export const ChartSparkLineUptimeData: FC<\n",
      "  ChartSparkLineUptimeDataProps\n",
      "> = ({}: ChartSparkLineUptimeDataProps) => {\n",
      "  const {\n",
      "    data: responseUptime = { data: [] },\n",
      "    isLoading,\n",
      "    isSuccess,\n",
      "  } = useGetUptimeDataQuery();\n",
      "\n",
      "  // https://apexcharts.com/docs/series/ for docs on data formatting\n",
      "  const seriesDataUptime = useMemo(() => {\n",
      "    if (responseUptime?.data?.length === 0) {\n",
      "      return null;\n",
      "    }\n",
      "\n",
      "    // do this before sorting so we get the most recent data points\n",
      "    const seriesDataUptime: ConnectivityData[] = responseUptime?.data?.slice(\n",
      "      0,\n",
      "      200,\n",
      "    );\n",
      "\n",
      "    // sort the data so it's in chronological order for the chart\n",
      "    seriesDataUptime.sort((a, b) => a.time.localeCompare(b.time));\n",
      "\n",
      "    const uptimeSeries = seriesDataUptime.slice().map((item) => ({\n",
      "      x: item.time,\n",
      "      y: item.success,\n",
      "    }));\n",
      "\n",
      "    return [\n",
      "      {\n",
      "        name: 'Uptime',\n",
      "        data: uptimeSeries,\n",
      "      },\n",
      "    ];\n",
      "  }, [responseUptime]);\n",
      "\n",
      "  return (\n",
      "    <Component\n",
      "      options={{\n",
      "        chart: {\n",
      "          sparkline: {\n",
      "            enabled: true,\n",
      "          },\n",
      "        },\n",
      "      }}\n",
      "      series={seriesDataUptime}\n",
      "      isLoading={isLoading}\n",
      "      isSuccess={isSuccess}\n",
      "    />\n",
      "  );\n",
      "};\n",
      "\n",
      "export default ChartSparkLineUptimeData;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "component_name = 'ChartSparkLineUptimeData'\n",
    "component_interface = f'{component_name}Props'\n",
    "\n",
    "query = f\"\"\"\n",
    "Create a React component utilizing imUp's API client and satisfying the following requirements:\n",
    "1. The component should be named '{component_name}'.\n",
    "2. The component should be a functional component of type '{component_interface}'.\n",
    "3. The component should enable ApexChart's 'sparkline' mode.\n",
    "\"\"\"\n",
    "\n",
    "results = qa_chain({\"query\": query})\n",
    "print(results[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It didn't generate the interface, so lets generate the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```ts\n",
      "export interface ChartSparkLineUptimeDataProps {}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "Create a React component typescript 'interface', satisfying the following requirements:\n",
    "1. The interface should be named '{component_interface}'.\n",
    "2. The file name to generate code for is '{component_name}.interface.ts'.\n",
    "3. The component code looks like the following:\n",
    "{results[\"result\"]}.\n",
    "4. Do not include the component code in the generated output.\n",
    "5. Parameters pulled from react-router-dom's 'useParams' hook should not be included in the interface.\n",
    "6. The code should export an interface with an empty props object if the React component does not use any of the properties of '{component_interface}':\n",
    "```tsx\n",
    "export interface {component_interface} {{}}\n",
    "```\n",
    "8. Fill in the following code with the props that the React component uses or follow rule #6:\n",
    "```tsx\n",
    "export interface {component_interface} {{\n",
    "  // fill in the props here\n",
    "}}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "results = qa_chain({\"query\": query})\n",
    "print(results[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
