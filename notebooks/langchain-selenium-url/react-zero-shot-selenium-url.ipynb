{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d5d4bf-dadf-4058-8024-9da9e1ebbc89",
   "metadata": {},
   "source": [
    "# React Zero-Shot from URL Sources with LangChain and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1155f",
   "metadata": {},
   "source": [
    "## ChromaDB Persistence\n",
    "\n",
    "Each notebook that uses ChromaDB follows the same pattern for persistence.\n",
    "\n",
    "If the directory already exists that ChromaDB would be writing it's data to, it will load the existing database. If the directory does not exist, it will create a new database.\n",
    "\n",
    "If you change parameters that affect the embeddings generation (like swapping in a new PDF file), you'll need to delete the database directory to force a new database to be created.\n",
    "\n",
    "This can be done by running the following from the root of the repository. If the ChromaDB directory is `data/chromadb/url_source`, you'd run the following to delete it:\n",
    "\n",
    "```sh\n",
    "rm -rf data/chromadb/url_source\n",
    "```\n",
    "\n",
    "or if you run into permissions issues:\n",
    "\n",
    "```sh\n",
    "sudo rm -rf data/chromadb/url_source\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecb0037-7968-4976-8324-9048df23d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ****************** [START] Google Cloud project settings ****************** #\n",
    "project =  os.getenv('GCP_PROJECT')\n",
    "location = os.environ.get('GCP_REGION', 'us-central1')\n",
    "# ******************* [END] Google Cloud project settings ******************* #\n",
    "\n",
    "\n",
    "# *********************** [START] Embeddings config ************************* #\n",
    "# set rate limiting options for Vertex AI embeddings\n",
    "embeddings_requests_per_minute = 100\n",
    "embeddings_num_instances_per_batch = 5\n",
    "# *********************** [END] Embeddings config *************************** #\n",
    "\n",
    "\n",
    "# ********************** [START] data directory config ********************** #\n",
    "# local directory to write chroma db persistence to\n",
    "# or pull files like PDFs from to create embeddings\n",
    "from helpers.files import get_data_dir\n",
    "data_dir = get_data_dir()\n",
    "\n",
    "chroma_db_dir = f'{data_dir}/chromadb'\n",
    "chroma_db_url_source_dir = f'{chroma_db_dir}/url_source'\n",
    "# *********************** [END] data directory config *********************** #\n",
    "\n",
    "\n",
    "# ********************** [START] LLM data config **************************** #\n",
    "from helpers.files import file_exists\n",
    "\n",
    "collection_name = 'url-source'\n",
    "load_documents = True\n",
    "if file_exists(chroma_db_url_source_dir):\n",
    "    load_documents = False\n",
    "# *********************** [END] LLM data config ***************************** #\n",
    "\n",
    "\n",
    "# *********************** [START] URL tool config *************************** #\n",
    "urls = [\n",
    "    \"https://www.imup.io/\",\n",
    "]\n",
    "\n",
    "# tool config for the langchain react agent\n",
    "tool_name = \"imUp.io marketing document reader\"\n",
    "tool_description = \"Use this to read imUp.io's mission, how it works, testimonials, plans, FAQ, and more.\"\n",
    "# *********************** [END] URL tool config ***************************** #\n",
    "\n",
    "\n",
    "# ******************* [START] vector db retriever config ******************** #\n",
    "# experiment with:\n",
    "# - mmr\n",
    "# - similarity\n",
    "db_search_type = \"similarity\"\n",
    "db_search_kwargs = {\"k\": 5}\n",
    "# ********************* [END] vector db retriever config ******************** #\n",
    "\n",
    "\n",
    "# *********************** [START] LLM parameter config ********************** #\n",
    "# Vertex AI model to use for the LLM\n",
    "model_name='text-bison@002'\n",
    "\n",
    "# maximum number of model responses generated per prompt\n",
    "candidate_count = 1\n",
    "\n",
    "# determines the maximum amount of text output from one prompt.\n",
    "# a token is approximately four characters.\n",
    "max_output_tokens = 1024\n",
    "\n",
    "# temperature controls the degree of randomness in token selection.\n",
    "# lower temperatures are good for prompts that expect a true or\n",
    "# correct response, while higher temperatures can lead to more\n",
    "# diverse or unexpected results. With a temperature of 0 the highest\n",
    "# probability token is always selected. for most use cases, try\n",
    "# starting with a temperature of 0.2.\n",
    "temperature = 0.2\n",
    "\n",
    "# top-p changes how the model selects tokens for output. Tokens are\n",
    "# selected from most probable to least until the sum of their\n",
    "# probabilities equals the top-p value. For example, if tokens A, B, and C\n",
    "# have a probability of .3, .2, and .1 and the top-p value is .5, then the\n",
    "# model will select either A or B as the next token (using temperature).\n",
    "# the default top-p value is .8.\n",
    "top_p = 0.8\n",
    "\n",
    "# top-k changes how the model selects tokens for output.\n",
    "# a top-k of 1 means the selected token is the most probable among\n",
    "# all tokens in the model’s vocabulary (also called greedy decoding),\n",
    "# while a top-k of 3 means that the next token is selected from among\n",
    "# the 3 most probable tokens (using temperature).\n",
    "top_k = 40\n",
    "\n",
    "# how verbose the llm and langchain agent is when thinking\n",
    "# through a prompt. you're going to want this set to True\n",
    "# for development so you can debug its thought process\n",
    "verbose = True\n",
    "# *********************** [END] LLM parameter config ************************ #\n",
    "\n",
    "\n",
    "# ********************** [START] Configuration Checks *********************** #\n",
    "if not project:\n",
    "    raise Exception('GCP_PROJECT environment variable not set')\n",
    "# *********************** [END] Configuration Checks ************************ #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06539965",
   "metadata": {},
   "source": [
    "## Import and Initialize Vertex AI Client\n",
    "\n",
    "This will complain about not having cuda drivers and the GPU not being used. You can safely ignore that. If you want to use the GPU, that's possible in Linux with Docker, but you'll need to set up a non-containerized development environment to use GPUs with MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076f2cc2-ed7b-4381-ad68-e6c21b811f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 21:52:31.408295: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-16 21:52:31.409877: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 21:52:31.428254: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-16 21:52:31.428279: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-16 21:52:31.428292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-16 21:52:31.432013: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-16 21:52:31.432606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-16 21:52:31.921302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK version: 1.38.1\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=project, location=location)\n",
    "\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67560cae",
   "metadata": {},
   "source": [
    "## Import LangChain\n",
    "\n",
    "This doesn't actually initialize anything, it just lets us print the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87c2a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 0.0.350\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae8d34",
   "metadata": {},
   "source": [
    "## Configure LLM with Vertex AI\n",
    "\n",
    "- https://github.com/langchain-ai/langchain/blob/34e6f3ff72067af3265341bcea7983c106f15a74/libs/community/langchain_community/llms/vertexai.py#L203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac3671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=model_name,\n",
    "    max_output_tokens=max_output_tokens,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    top_k=top_k,\n",
    "    verbose=verbose,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687b604",
   "metadata": {},
   "source": [
    "## Initialize Embeddings Function with Vertex AI\n",
    "\n",
    "There are other options for creating embeddings. I was interested in sticking with Google products here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b33162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.vertexai.VertexAIEmbeddings.html\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    requests_per_minute=embeddings_requests_per_minute,\n",
    "    num_instances_per_batch=embeddings_num_instances_per_batch,\n",
    "    model_name = \"textembedding-gecko@latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e3f0e",
   "metadata": {},
   "source": [
    "## Load Sites into LLM\n",
    "\n",
    "This can include YouTube videos and Google Maps, not just regular HTML/SPA sites.\n",
    "\n",
    "Reference: https://python.langchain.com/docs/integrations/document_loaders/url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b29a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "\n",
    "loader = SeleniumURLLoader(\n",
    "  urls=urls,\n",
    "  browser='firefox',\n",
    "  headless=True,\n",
    ")\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.url_selenium.SeleniumURLLoader.html#langchain.document_loaders.url_selenium.SeleniumURLLoader.load_and_split\n",
    "documents = loader.load_and_split()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02d5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"Home\\n\\nOur mission\\n\\nHow it works\\n\\nTestimonials\\n\\nPlans\\n\\nFAQ\\n\\nSupport\\n\\nOrgs\\n\\nLogin\\n\\nBusiness\\n\\nMeasure your d*mn internet\\n\\nFind the best internet available\\n\\nFind the best internet available\\n\\nthen measure it.\\n\\nFind it\\n\\nMeasure it\\n\\nOur Mission\\n\\nCrowdsourcing internet information and taking the finger pointing out of problems.\\n\\nWe're here to provide insight into the internet at large. We gather data about providers, their plans, and their performance from your perspective -- and give it to you, for free.\\n\\nCheck our internet providers page to make sure you're getting a good deal in your area. Then use our app to measure it 24/7 and make sure you're getting what you pay for. Catch any disconnections and slow speeds and export the data as proof to help track down where issues may be coming from.\\n\\nNow that most of our lives revolve around being online, we want to make sure you have the best possible connection you can get.\\n\\nBrad Miller\\n\\nCo-Founder of imup\\n\\nELI5:\\xa0What does imUp do?\\n\\nWe crowdsource ISP information like pricing, advertised speeds, ratings, actual customer speeds and\\xa0connection status if they're running our app -- and then we give it all to you.\\n\\nOnce you've found awesome internet: install the imUp app on any computer, Raspberry Pi, server, firewall, router, smart car, power station, drilling rig, satellite, container, smart toaster, or just about anywhere you want to measure internet connectivity.\\n\\nThe app sends your metrics to our platform for you and others to view. We can notify you if you go offline or experience slow speeds, and you can export all this data if you need to chat with your ISP\\xa0about issues.\\n\\nAlso, it's\\n\\nfree so that's pretty\\n\\ncool.\\n\\ntl;dr:\\xa0check internet price in area. measure connection. get tweet / email if go offline or slow speed. help others get good internet. profit\\n\\ntl;dr:\\xa0check internet price in area. measure connection. get tweet / email if go offline or slow speed. help others get good internet. profit\\n\\nhow it works\\n\\nThe imUp process &\\xa0services\\n\\nIt's pretty simple. Just sign up, install, and run the app. You can see the quality of your connection in the dashboard anytime & anywhere. We'll let you know when you lose connection or experience slow speeds. Your speed data is also shared (anonymously) with others around you to help crowdsource good internet plans &\\xa0providers.\\n\\nHave questions or concerns?\\n\\nFeel free to\\n\\nemail us.\\n\\nCommon Questions\\n\\nGo to FAQ Page\\n\\nHow to get started\\n\\n1. Register\\n\\nBrowse to app.imup.io\\n\\nRegister using Google, Facebook, Twitter, or your email address\\n\\nRegister\\n\\n2. Download &\\xa0install the app\\n\\nBrowse to app.imup.io/downloads\\n\\nPick the download for your operating system (mac, windows, linux, docker, etc)\\n\\nOnce you've installed the app, plug in your email address and you'll see metrics appear in your dashboard in less than 15 minutes.\\n\\nDownload\\n\\n3. Fill out your profile\\n\\nBrowse to your profile\\n\\nAdd your zipcode &\\xa0internet provider information (provider, speeds, price) to help crowdsource pricing for others in your area.\\n\\nProfile\\n\\n4. Subscribe to a plan\\n\\nYou can run the app for free with no strings attached, but we also offer additional features &\\xa0benefits under our paid plans.\\n\\nReview the plans we offer and subscribe to them if you want extended data storage or other features.\\n\\nshopping for new internet\\n\\nISPs in your area\\n\\nCheck out the average price &\\xa0speeds other folks in your area are paying for. See what they're rating their providers too.\\n\\nall of our neighbors are disconnected too\\n\\nLocal pricing &\\xa0connection stats\\n\\nShopping for new internet or simply looking to make sure you're still getting a good deal? We give you speeds, prices, actual customer speeds and connection status. Easily verify if connection problems are yours, or if you're part of a larger outage.\\n\\nNotifications\\n\\nEmail notifications\\n\\nGet real-time alerts about your connection. If you're out of town, asleep, or playing games -- never let issues go undetected.\" metadata={'source': 'https://www.imup.io/', 'title': 'imUp.io - measure your d*mn internet', 'description': \"Measure your internet speeds & performance 24/7. Check ISP prices, speeds, and ratings in your area. See your neighbors speeds and if they're online.\", 'language': 'en'}\n",
      "page_content='Notifications\\n\\nEmail notifications\\n\\nGet real-time alerts about your connection. If you\\'re out of town, asleep, or playing games -- never let issues go undetected.\\n\\nIf we notice that you have gone offline or if your most recent speed test is slower than your personal threshold, we can notify you via email or twitter.\\n\\nbabe, is the internet down again?\\n\\nConnectivity\\n\\nMeasure and record downtime 24/7. Whether you\\'re asleep, at work, or on vacation -- we\\'re keeping an eye on your connection for you. Receive offline notifications via email or twitter.\\n\\ngood lord this download is taking forever\\n\\nSpeed Testing\\n\\nView and export historical speed test data including download &\\xa0upload speeds, as well as latency. Away from home or laying in bed?\\xa0Run a speed test on your computer any time from anywhere with a single click.\\n\\nam I\\xa0lagging?!\\n\\nConnection Health\\n\\nNow you can view and export historical metrics such as latency, RTT, and packet loss. If you\\'re experiencing connectivity issues while working from home or gaming, this data will help you pinpoint if the issue is on your end or not.\\n\\nNeed to measure the internet at more than one location?\\n\\nAt the request of the community, we built\\n\\nimUp Orgs. You can now install the imUp app on all of your computers, equipment, or IoT\\xa0to see connection statistics for all of them in a single dashboard.\\n\\nNo monitoring server, no VPN tunnels, no firewall rules,\\n\\nno worries.\\n\\nCheck out orgs\\n\\nWorldwide\\n\\nNow serving people and businesses in over 80 countries around the world\\n\\nimUp is checking the internet provided by 50+\\xa0ISPs on every continent except Antartica (soon). We\\'re measuring fiber, cable, wireless, and even satellite connections to ensure stability and performance for customers large and small.\\n\\nLogin\\n\\ntestimonials\\n\\nWhat our customers say about us\\n\\nSee our reviews here\\n\\n\"After using imUp we realized we were getting speeds significantly less than we were paying for (20mbps instead of 200mbps!). Adding Kristin as an authorized user to the account was super quick and easy. She was able to call our provider on our behalf and talk to them about the degraded service. Afterwards our provider sent out a tech (for free) who replaced our router with a newer, better model, and he replaced a bunch of old connectors outside the home and in the attack to improve the service. He was also able to provide additional insight into some of the causes of our problems which lead us to getting a new network card for our computer. We have been dealing with frequent network drops and decreased speeds for so long, we became accustomed to it. Now it\\'s like the world around us is 10x faster, and it wouldn\\'t have happened if it wasn\\'t for imUp. Thank you!!\"\\n\\nMiranda H.\\n\\nAT&T\\n\\n\"This service is definitely an invaluable asset for making your internet provider accountable. I like to call it my internet insurance! \\xa0Give it a try; you won’t believe the amount of internet service you pay for and do not receive! \\xa0This worth is priceless!\"\\n\\nKirbie T.\\n\\nOneSource\\n\\n\"This tool has been fantastic for measuring my internet performance!\"\\n\\nKara G.\\n\\nAT&T\\n\\n\"I was constantly experiencing disconnections with my provider. My biggest issue is that 2 hours of downtime could mean literally thousands of potential dollars I\\'m losing out on. imUp gives me the insight I need into my connection to be able to successfully negotiate a credit. Worth it 100%\"\\n\\nChris C.\\n\\nonesource' metadata={'source': 'https://www.imup.io/', 'title': 'imUp.io - measure your d*mn internet', 'description': \"Measure your internet speeds & performance 24/7. Check ISP prices, speeds, and ratings in your area. See your neighbors speeds and if they're online.\", 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dcfa0",
   "metadata": {},
   "source": [
    "## Create Embeddings Database\n",
    "\n",
    "This is written with persistence and will not re-create the database if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa97150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if load_documents:\n",
    "  # https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html#langchain.vectorstores.chroma.Chroma.from_documents\n",
    "  db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    collection_name=collection_name,\n",
    "    persist_directory=chroma_db_url_source_dir,\n",
    "  )\n",
    "else:\n",
    "  db = Chroma(\n",
    "    persist_directory=chroma_db_url_source_dir,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collection_name,\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6713ce",
   "metadata": {},
   "source": [
    "## Persist the Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4ce2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this would be safe to run in all circumstances but\n",
    "# it feels weird to try writing if there are no changes anyway\n",
    "if load_documents:\n",
    "  db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50abcc",
   "metadata": {},
   "source": [
    "## Initialize Retrieval QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c90cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(\n",
    "      search_type=db_search_type,\n",
    "      search_kwargs=db_search_kwargs,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95d41e8",
   "metadata": {},
   "source": [
    "## Configure Retrieval QA Chain Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ce535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentExecutor\n",
    "\n",
    "tools = [\n",
    "  Tool(\n",
    "    name=tool_name,\n",
    "    func=retrieval_qa.run,\n",
    "    description=tool_description,\n",
    "  ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d36b2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize ReAct Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f775d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "\n",
    "# initialize ReAct agent\n",
    "react = initialize_agent(\n",
    "  tools,\n",
    "  llm,\n",
    "  agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "  verbose=True,\n",
    "  # https://python.langchain.com/docs/modules/agents/how_to/max_time_limit\n",
    "  max_execution_time=60,\n",
    "  # By default, the early stopping uses the force method which\n",
    "  # just returns that constant string. Alternatively, you could\n",
    "  # specify the generate method which then does one FINAL pass\n",
    "  # through the LLM to generate an output.\n",
    "  early_stopping_method=\"generate\",\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "  agent=react.agent,\n",
    "  tools=tools,\n",
    "  verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eecac6",
   "metadata": {},
   "source": [
    "## Ask something about the URL content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ce8fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m imUp.io offers different plans, so I need to check the pricing section of their marketing document.\n",
      "Action: imUp.io marketing document reader\n",
      "Action Input: pricing\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The pricing for imUp's services varies depending on the plan you choose. They offer a free plan with basic features, as well as paid plans with additional features and benefits. The paid plans range from $10 per user per year for the Lite plan, to $30 per user per year for the Integrity plan.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the pricing for imUp.io's services.\n",
      "Final Answer: imUp.io offers a free plan with basic features, as well as paid plans with additional features and benefits. The paid plans range from $10 per user per year for the Lite plan, to $30 per user per year for the Integrity plan.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The lite plan should have some basic features.\n",
      "Action: imUp.io marketing document reader\n",
      "Action Input: Plans\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m imUp offers three pricing plans: Lite, Integrity, and Reporting. The Lite plan is $1 per user per month and includes downtime monitoring, speed testing, remote speed testing, downtime notifications, slow speed notifications, and data export. The Integrity plan is $3 per user per month and includes all of the features of the Lite plan, plus 1 month of metrics storage and weekday email support. The Reporting plan is $30 per user per year and includes all of the features of the Integrity plan, plus 2 days of metrics storage and weekday email support.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The Lite plan includes downtime monitoring, speed testing, remote speed testing, downtime notifications, slow speed notifications, and data export.\n",
      "Final Answer: Downtime monitoring, speed testing, remote speed testing, downtime notifications, slow speed notifications, and data export.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Downtime monitoring, speed testing, remote speed testing, downtime notifications, slow speed notifications, and data export.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How much does imUp.io cost?\"\n",
    "agent_executor.run(question)\n",
    "\n",
    "question = \"What features are included in imUp.io's lite plan?\"\n",
    "agent_executor.run(question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
